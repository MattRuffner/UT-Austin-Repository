{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNaI6ZEbU5Eu"
   },
   "source": [
    "# <p style=\"text-align: center;\">MIS 382N: ADVANCED PREDICTIVE MODELING - MSBA</p>\n",
    "# <p style=\"text-align: center;\">Assignment 1</p>\n",
    "## <p style=\"text-align: center;\">Total points: 85</p>\n",
    "## <p style=\"text-align: center;\">Due: Monday, September 14 submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Your partner needs to be from the same section. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTEID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TA know. \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xo0nJm8jVIvq"
   },
   "source": [
    "# Question 1: Challenges in Data Science (10 pts)\n",
    "\n",
    "Refer to the Domino guide under Modules --> Additional Resources\n",
    "\n",
    "Section 2 describes 8 Challenges. You may have personally encountered or heard of somebody else who encountered some of these challenge. If so, please write 1-2 paragraphs on what situation was encountered and how it mapped into one the mentioned challenges. If not, think of a hypothetical case and do the same exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of right problem that had already been solved but was irreproducible was when a business analyst at a finance company created a monthly report using simpler steps and software, and later realized that essentially the exact same results could have been obtained from using AutoCAD. However, when attempting to follow the procedure for the AutoCAD process, he realized that the procedure was flawed: he could not reproduce the right results. In other words, it turned out that he found a better solution to a problem that previously had an incorrectly documented and possibly outdated process.\n",
    "\n",
    "An example of solving the right problem in the wrong way would be using a robust but low-explainability predictive model to decide on a course of action, when the task is really to develop a model that is intuitive enough to convince managers and non-data-scientists to adopt it. The \"correct answer\" is technically achieved, but the true goal of mass usability is not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEJzKVrnVNX8"
   },
   "source": [
    "# Question 2: Guess the coin (5+5 = 10 points)\n",
    "\n",
    "Assume we are playing a guessing game with a friend. The friend has three coins at hand:\n",
    "* **Coin A**: a fair coin with equal probability of being head (H ) or tail (T)\n",
    "* **Coin B**: a biased coin with a probability of 0.75 being head (H)\n",
    "* **Coin C**: a coin with a probability of $P^*(H)$ being head (H)\n",
    "\n",
    "The friend secretly picked one of the coins, randomly flipped it a few times, and get a sequence of *HTHHTT* (all of which come from the same coin he picked). \n",
    "\n",
    "1. If you had to choose between whether **Coin A** or **Coin B** was used, and you prefer the one which is more likely, which one will you choose?  (5 points)\n",
    "2. What would be the value of  $P^*(H)$ such that **Coin C** corresponds to the most likely (among infinite possible coins) coin to have produced the observed sequence?(i.e. provide  an analytical derivation for $P^*(H)$ using maximum likelihood estimation (MLE)).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the spirit of M.L.P., our set of possible distributions are the ones given: A being a binomial distribution of p = 0.5 and B being one of p = 0.75 (p being probability of heads). The question is which distribution in the set maximizes the probability of getting the sequence *HTHHTT* (assuming independent flips).\n",
    "\n",
    "Therefore, it is clear to see that with distribution A, the probability is 0.5^6 = 0.015625, whereas with distribution B, it is 0.75^3 \\* 0.25^3 = 0.00659179687. Therefore, A maximizes the probability, and therefore it is more likely to have been coin A that was flipped.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability is p^3 * (1-p)^3, and to maximize that, we look at the first-order condition, set it equal to 0, and then solve:\n",
    "\n",
    "-3 * (1-p)^2 * p^3 + (1-p)^3 * 3 * p^2 = 0\n",
    "\n",
    "You also need second-order condition to be negative:\n",
    "\n",
    "6 * p * (1 - 6 * p + 10 * p^2 - 5 * p^3) < 0\n",
    "\n",
    "The two conditions solve out to be p = 0.5, or the exact same as Coin A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ybdQEknZyQH"
   },
   "source": [
    "# Question 3: Multiple Linear Regression (30 pts)\n",
    "\n",
    "In this problem you will try to estimate the height of a fish based on some other properties using MLRR. Use the following code to import the Fish market prices dataset in python. The dataset is taken from https://www.kaggle.com/aungpyaeap/fish-market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "3gPvvi5SbFuO",
    "outputId": "cff835be-39ce-496d-bcc4-24e00da7521f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Weight  Length1  Length2  Length3   Height   Width\n",
       "Species                                                    \n",
       "Bream     242.0     23.2     25.4     30.0  11.5200  4.0200\n",
       "Bream     290.0     24.0     26.3     31.2  12.4800  4.3056\n",
       "Bream     340.0     23.9     26.5     31.1  12.3778  4.6961\n",
       "Bream     363.0     26.3     29.0     33.5  12.7300  4.4555\n",
       "Bream     430.0     26.5     29.0     34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kp1rcYK5fRWK"
   },
   "source": [
    "Here,\n",
    "1. Species: Species name of fish\n",
    "2. Weight: Weight of fish in gram\n",
    "3. Length1: Vertical length in cm\n",
    "4. Length2: Diagonal length in cm\n",
    "5. Length3: Cross length in cm\n",
    "6. Height: Height in cm\n",
    "7. Width: Diagonal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GG5IzhNd0Xt"
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "X = df.drop(['Weight'], axis=1)\n",
    "y = df['Weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gODjWSNcdHhb"
   },
   "source": [
    "Consider the `Weight` column to be your target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMUKzagncX0O"
   },
   "source": [
    "a. (2 pts)  Print the shape (number of rows and columns) of the feature matrix X, and print the first 5 rows.\n",
    "\n",
    "b. (6 pts) Using ordinary least squares, fit a multiple linear regression (MLR) on all the feature variables using the entire dataset. Report the regression coefficient of each input feature and evaluate the model using mean absolute error (MAE). Example of ordinary least squares in Python is shown in Section 1.1.1 of http://scikit-learn.org/stable/modules/linear_model.html.\n",
    "\n",
    "c. (6 pts) Split the data into a training set and a test set, using the train_test_split with test_size = 0.25 and random_state = 50. Fit an MLR using the training set. Evaluate the trained model using the training set and the test set, respectively. Compare the two MAE values thus obtained. Report the [$R^2$ (coefficient of determination)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) value.\n",
    "\n",
    "d. (5 pts) Calculate the pearson correlation matrix of the independent variables in the training set. Report the variables which have magnitude of correlation greater than 0.8 w.r.t the variable 'Length2'. Now, plot a pairplot based on Species column as seen in the 2nd plot [here](https://seaborn.pydata.org/generated/seaborn.pairplot.html). How does the pairplot validate your previous answer?\n",
    "\n",
    "e. (6 pts) Plot the histogram of Y_train and see its distribution. Now take log of Y_train and plot its histogram. Now run regression again after taking log and compare the MAE. You need to do np.exp(predictions) to bring them back to original scale, and then calculate MAE and $R^2$. Explain the results.\n",
    "\n",
    "f. (5 pts) Rank the features in descending order based on their significance. You might find this link to be helpful: http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html.\n",
    "\n",
    "g. (Bonus question - 5 pts) Use the Species column for one-hot encoding and perform part c of this question. Explain your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'159, 6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Species'] = X.index\n",
    "\n",
    "str(len(X.index)) + ', ' + str(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bream</th>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Length1  Length2  Length3   Height   Width\n",
       "Species                                            \n",
       "Bream       23.2     25.4     30.0  11.5200  4.0200\n",
       "Bream       24.0     26.3     31.2  12.4800  4.3056\n",
       "Bream       23.9     26.5     31.1  12.3778  4.6961\n",
       "Bream       26.3     29.0     33.5  12.7300  4.4555\n",
       "Bream       26.5     29.0     34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(['Species'], axis=1)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data=X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -80.30295196,   79.88863137,   32.53538142,    5.25098766,\n",
       "         -0.51543798,  164.72266067,  137.94890963, -208.42935662,\n",
       "        103.03995457,  446.07331747,   93.87416805])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(X.values, y.values)\n",
    "\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Length1', 'Length2', 'Length3', 'Height', 'Width', 'Species_Parkki',\n",
       "       'Species_Perch', 'Species_Pike', 'Species_Roach', 'Species_Smelt',\n",
       "       'Species_Whitefish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.29370097790675"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.abs(reg.predict(X) - y.values)) / len(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.29370097790674"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrue = y.values\n",
    "yPred = reg.predict(X)\n",
    "\n",
    "mean_absolute_error(yTrue, yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-119.64571799,  134.46028493,   18.37070533,    1.28084641,\n",
       "         11.36606758,  188.1110623 ,   65.68407932, -292.88301532,\n",
       "        121.30969644,  505.55889476,   72.90065467])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(X_train.values, y_train.values)\n",
    "\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.964048005461194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.abs(reg.predict(X_train) - y_train.values)) / len(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9463762188356688"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_train.values, reg.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.20532755690006"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.abs(reg.predict(X_test) - y_test.values)) / len(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885793687939455"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test.values, reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Length1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999399</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.845798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length2</th>\n",
       "      <td>0.999399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992702</td>\n",
       "      <td>0.606298</td>\n",
       "      <td>0.853645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length3</th>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.992702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678908</td>\n",
       "      <td>0.858384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.606298</td>\n",
       "      <td>0.678908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <td>0.845798</td>\n",
       "      <td>0.853645</td>\n",
       "      <td>0.858384</td>\n",
       "      <td>0.766986</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Length1   Length2   Length3    Height     Width\n",
       "Length1  1.000000  0.999399  0.990034  0.587997  0.845798\n",
       "Length2  0.999399  1.000000  0.992702  0.606298  0.853645\n",
       "Length3  0.990034  0.992702  1.000000  0.678908  0.858384\n",
       "Height   0.587997  0.606298  0.678908  1.000000  0.766986\n",
       "Width    0.845798  0.853645  0.858384  0.766986  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Weight'], axis=1)\n",
    "\n",
    "X['Species'] = X.index\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=50)\n",
    "\n",
    "pearson = X_train.corr()\n",
    "\n",
    "pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Length1', 'Length2', 'Length3', 'Width'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson['Length2'][abs(pearson['Length2']) > 0.8].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e4f979df2140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ticks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Species\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "g = sns.pairplot(X_train, hue=\"Species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pairplot validates the Pearson correlation matrix because the latter is basically a numerical summarization of the former's visuals. For example, *Height* and *Length1* have a clear low correlation of 0.587997, and that is confirmed by the scattered, less-than-straight nature of the data points in the plot of *Length1* and *Height*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(y_train).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data=X, drop_first=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=50)\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(X_train.values, np.log(y_train).values)\n",
    "\n",
    "sum(np.abs(np.exp(reg.predict(X_train)) - y_train.values)) / len(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train.values, np.exp(reg.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain the result above (how?)** Perhaps the lower M.S.E. value and higher R^2 using this method are due to the fact that an error-minimizing O.L.S. model using logged Y values is good to the extent that even exponentiating those values still maintains overall less error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somehow the code does not work even though I'm pretty sure it is exactly the same syntax as in the provided link\n",
    "# Not sure what the bug here is\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "selector = RFE(reg, n_features_to_select=None, step=1, verbose=0)\n",
    "\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9h7-QI6VvKf"
   },
   "source": [
    "# Question 4 (30 pts)\n",
    "\n",
    "Using the same data from the previous question, in this question you will explore the application of Lasso and Ridge regression using sklearn package in Python. Use the same train and test data with additional augmented columns from before. Scale the data so that each of the independent variables have zero mean and unit variance. You can use the [sklearn.preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) function for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMK1ZYt0V9rE"
   },
   "source": [
    "    from sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV, LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 (30 pts)\n",
    "Using the same data from the previous question, in this question you will explore the application of Lasso and Ridge regression using sklearn package in Python. Use the same train and test data with additional augmented columns from before. Scale the data so that each of the independent variables have zero mean and unit variance. You can use the [sklearn.preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV, LassoCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use sklearn.linear_model.Lasso and sklearn.linear_model.Ridge classes to do a [5-fold cross validation](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py) using sklearn's [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html). For the sweep of the regularization parameter, we will look at a grid of values ranging from $\\lambda = 10^{10}$ to $\\lambda = 10^{-2}$. In Python, you can consider this range of values as follows:\n",
    "\n",
    "      import numpy as np\n",
    "\n",
    "      alphas =  10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "  Report the best chosen $\\lambda$ based on cross validation. The cross validation should happen on your training data using  average MAE as the scoring metric. (8pts)\n",
    "\n",
    "2) Run ridge and lasso for all of the alphas specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; the plots for different features for a method should be on the same plot. What do you qualitatively observe when value of the regularization parameter is changed? (7pts)\n",
    "\n",
    "3) Run least squares regression, ridge, and lasso on the training data. For ridge and lasso, use only the best regularization parameter. Report the prediction error (MAE) on the test data for each. (5pts)\n",
    "\n",
    "4) Run lasso again with cross validation using [sklearn.linear_model.LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). Set the cross validation parameters as follows:\n",
    "\n",
    "    LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "Report the best $\\lambda$ based on cross validation. Run lasso on the training data using the best $\\lambda$ and report the coefficeints for all variables. (5pts)\n",
    "\n",
    "5) Why did we have to scale the data before regularization? (5pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVQXFJbmWGva"
   },
   "source": [
    "# Question 5 (5 pts)\n",
    "Lasso and ridge regularization techniques are often used to combat overfitting during linear regression. Which of the two yields more sparse models (i.e. fewer number of parameters) when the tuning parameter $\\lambda$ is sufficiently large (but not infinite)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfqTtPThV4Z6"
   },
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW1-F20-Q-MIS382N.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
